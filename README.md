# AI Medical Chatbot 2.0 (with Vision and Voice)

A smart AI Medical Chatbot integrated with advanced vision and voice capabilities built using open-source AI tools. This project leverages the Meta Llama3 vision 90b multimodal large language model for powerful image and text understanding, OpenAI Whisper for speech-to-text, and ElevenLabs for natural text-to-speech to create an interactive AI Doctor assistant. The chatbot is designed as a Gradio app providing a conversational interface for healthcare queries with vision and voice support.

---

## Features

- Multimodal AI Medical Chatbot that understands text, images, and voice input
- Speech-to-text powered by OpenAI Whisper for accurate voice recognition
- Text-to-speech using ElevenLabs for realistic AI voice responses
- Utilizes Meta Llama3 vision 90b for deep understanding of medical images and text
- Interactive web-based interface built with Gradio framework
- Supports conversational AI for personalized healthcare assistance

---

## Technologies Used

- Meta Llama3 vision 90b (Multimodal Large Language Model)
- OpenAI Whisper (Speech-to-Text)
- ElevenLabs (Text-to-Speech)
- Gradio (Web UI Framework)
- gTTS (Google Text-to-Speech) for fallback TTS
- LangChain (AI agent and chaining models)
- Python programming language
- Other open-source AI libraries

---

## Project Layout & Architecture

The project is structured in phases:

1. **Multimodal AI Model Setup**: Integration of Llama3 vision model for image and text input  
2. **Speech-to-Text Setup**: Using Whisper for converting audio inputs to text  
3. **Text-to-Speech Setup**: Implementing ElevenLabs and gTTS for voice responses  
4. **Gradio App Setup**: Creating the user interface for chat interaction inclusive of voice and vision support

---

## Installation

### Prerequisites

- Python 3.8 or above  
- Git  
- API keys for ElevenLabs and OpenAI (if required)  
- Dependencies installed (see requirements.txt)

---
License
THis is under MIT license

--- AUthor
saniya chhabra
